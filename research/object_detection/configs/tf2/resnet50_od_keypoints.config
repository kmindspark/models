# Example config to launch the CenterNet model for keypoint estimation in
# Object Detection API.
# The model is trained on Move ML curated COCO keypoint dataset.
#
# Launch command:
# EXPERIMENT_NAME="center_net_resnet50_coco_pretrain_t1"
# google_xmanager launch image/understanding/object_detection/xm_tpu_launch_v2.py \
#  -- \
#  --job_name=$EXPERIMENT_NAME \
#  --model_dir=/cns/oz-d/home/move-ml/xm/centernet/$EXPERIMENT_NAME/ \
#  --tpu_type=jellyfish \
#  --tpu_topology=4x4 \
#  --xm_resource_alloc=group:perception/move-ml \
#  --pipeline_config_path=research/vision/pose/configs/center_net/resnet50_od_keypoints.config \
#  --xm_skip_launch_confirmation \
#  --noxm_tpu_worker_use_mpm \
#  --cell=oz

model {
  center_net {
    num_classes: 90
    feature_extractor {
      type: "resnet_v2_50"
    }
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 512
        max_dimension: 512
        pad_to_max_dimension: true
      }
    }
    object_detection_task {
      task_loss_weight: 1.0
      offset_loss_weight: 1.0
      scale_loss_weight: 0.1
      localization_loss {
        l1_localization_loss {
        }
      }
    }
    object_center_params {
      object_center_loss_weight: 1.0
      min_box_overlap_iou: 0.7
      max_box_predictions: 100
      classification_loss {
        penalty_reduced_logistic_focal_loss {
          alpha: 2.0
          beta: 4.0
        }
      }
    }
    # keypoint_label_map_path: "/cns/oz-d/home/move-ml/xm/centernet/label_map.txt"
    # keypoint_estimation_task {
    #   task_name: "human_pose"
    #   task_loss_weight: 1.0
    #   loss {
    #     classification_loss {
    #       penalty_reduced_logistic_focal_loss {
    #         alpha: 2.0
    #         beta: 4.0
    #       }
    #     }
    #     localization_loss {
    #       l1_localization_loss {
    #       }
    #     }
    #   }
    #   # target class: "person" keypoints.
    #   keypoint_class_name: "/m/01g317"
    #   keypoint_heatmap_loss_weight: 1.0
    #   keypoint_offset_loss_weight: 1.0
    #   keypoint_regression_loss_weight: 0.1
    # }
  }
}

train_config: {

  batch_size: 128
  num_steps: 1400000

  data_augmentation_options {
    random_horizontal_flip {
      keypoint_flip_permutation: 0
      keypoint_flip_permutation: 2
      keypoint_flip_permutation: 1
      keypoint_flip_permutation: 4
      keypoint_flip_permutation: 3
      keypoint_flip_permutation: 6
      keypoint_flip_permutation: 5
      keypoint_flip_permutation: 8
      keypoint_flip_permutation: 7
      keypoint_flip_permutation: 10
      keypoint_flip_permutation: 9
      keypoint_flip_permutation: 12
      keypoint_flip_permutation: 11
      keypoint_flip_permutation: 14
      keypoint_flip_permutation: 13
      keypoint_flip_permutation: 16
      keypoint_flip_permutation: 15
    }
  }

  data_augmentation_options {
    random_crop_image {
      min_aspect_ratio: 0.5
      max_aspect_ratio: 1.7
      random_coef: 0.25
    }
  }

  data_augmentation_options {
    random_adjust_hue {
    }
  }

  data_augmentation_options {
    random_adjust_contrast {
    }
  }

  data_augmentation_options {
    random_adjust_saturation {
    }
  }

  data_augmentation_options {
    random_adjust_brightness {
    }
  }

  data_augmentation_options {
    random_absolute_pad_image {
       max_height_padding: 200
       max_width_padding: 200
       pad_color: [0, 0, 0]
    }
  }

  optimizer {
    adam_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 1e-3
          schedule {
           step: 90000
           learning_rate: 1e-4
          }
          schedule {
            step: 120000
            learning_rate: 1e-5
          }
        }
      }
    }
    use_moving_average: false
  }
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
}

train_input_reader: {
  label_map_path: "/cns/oz-d/home/move-ml/xm/centernet/label_map.txt"
  tf_record_input_reader {
    input_path: "/cns/oz-d/home/move-ml/datasets/mscoco2017_od_kp/coco_train.record-00???-of-00100"
  }
  num_keypoints: 17
}

eval_config: {
  metrics_set: "coco_detection_metrics"
  use_moving_averages: false
  num_visualizations: 10
  max_num_boxes_to_visualize: 20
  min_score_threshold: 0.2
  batch_size: 1;
}

eval_input_reader: {
  shuffle: false
  num_epochs: 1
  label_map_path: "models/research/object_detection/data/mscoco_label_map.pbtxt"
  tf_record_input_reader {
    input_path: "/cns/oz-d/home/move-ml/datasets/mscoco2017_od_kp/coco_val.record-00???-of-00010"
  }
  num_keypoints: 17
}
