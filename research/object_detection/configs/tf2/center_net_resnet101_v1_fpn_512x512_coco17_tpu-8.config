# CenterNet meta-architecture from the "Objects as Points" [1] paper
# with the ResNet-v2-101 backbone. The ResNet backbone has a few differences
# as compared to the one mentioned in the paper, hence the performance is
# slightly worse. This config is TPU comptatible.
# [1]: https://arxiv.org/abs/1904.07850
# EXPERIMENT_NAME="centernet_resnet50_od_coco"
# google_xmanager launch image/understanding/object_detection/xm_tpu_launch_v2.py \
#  -- \
#  --job_name=$EXPERIMENT_NAME \
#  --model_dir=/cns/oz-d/home/move-ml/xm/centernet/$EXPERIMENT_NAME/ \
#  --tpu_type=jellyfish \
#  --tpu_topology=2x2 \
#  --xm_resource_alloc=group:perception/visual-dynamics \
#  --pipeline_config_path=research/vision/pose/configs/center_net/resnet50_od_coco.config \
#  --eval_timeout=14400 \
#  --xm_skip_launch_confirmation \
#  --noxm_tpu_worker_use_mpm

model {
  center_net {
    num_classes: 90
    feature_extractor {
      type: "resnet_v2_50"
    }
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 512
        max_dimension: 512
        pad_to_max_dimension: true
      }
    }
    object_detection_task {
      task_loss_weight: 1.0
      offset_loss_weight: 1.0
      scale_loss_weight: 0.1
      localization_loss {
        l1_localization_loss {
        }
      }
    }
    object_center_params {
      object_center_loss_weight: 1.0
      min_box_overlap_iou: 0.7
      max_box_predictions: 100
      classification_loss {
        penalty_reduced_logistic_focal_loss {
          alpha: 2.0
          beta: 4.0
        }
      }
    }
  }
}

train_config: {

  batch_size: 128
  num_steps: 250000

  data_augmentation_options {
    random_horizontal_flip {
    }
  }

  data_augmentation_options {
    random_crop_image {
      min_aspect_ratio: 0.5
      max_aspect_ratio: 1.7
      random_coef: 0.25
    }
  }


  data_augmentation_options {
    random_adjust_hue {
    }
  }

  data_augmentation_options {
    random_adjust_contrast {
    }
  }

  data_augmentation_options {
    random_adjust_saturation {
    }
  }

  data_augmentation_options {
    random_adjust_brightness {
    }
  }

  data_augmentation_options {
    random_absolute_pad_image {
       max_height_padding: 200
       max_width_padding: 200
       pad_color: [0, 0, 0]
    }
  }

  optimizer {
    adam_optimizer: {
      epsilon: 1e-7  # Match tf.keras.optimizers.Adam's default.
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: 1e-3
          total_steps: 250000
          warmup_learning_rate: 2.5e-4
          warmup_steps: 5000
        }
      }
    }
    use_moving_average: false
  }
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false

  fine_tune_checkpoint_version: V2
  fine_tune_checkpoint: "/cns/iz-d/home/vighneshb/checkpoints/keras_app/resnet_v2_50/weights-1"
  fine_tune_checkpoint_type: "classification"
}

train_input_reader: {
  label_map_path: "/cns/oz-d/home/move-ml/xm/centernet/label_map.txt"
  tf_record_input_reader {
    input_path: "/cns/oz-d/home/move-ml/datasets/mscoco2017_od_kp/coco_train.record-00???-of-00100"
  }
  num_keypoints: 17
}

eval_config: {
  metrics_set: "coco_detection_metrics"
  use_moving_averages: false
  batch_size: 1;
}

eval_input_reader: {
  shuffle: false
  num_epochs: 1
  label_map_path: "models/research/object_detection/data/mscoco_label_map.pbtxt"
  tf_record_input_reader {
    input_path: "/cns/oz-d/home/move-ml/datasets/mscoco2017_od_kp/coco_val.record-00???-of-00010"
  }
}
